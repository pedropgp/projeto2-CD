{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas a serem utilizadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lendo a planilha de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinamento = pd.read_excel('tweets_xbox_treinamento.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando a base de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_char = [':', '.', ';', '\"', '?', '!', '{', '}', '*', '$', '[', ']', '(', ')', '/' '&', '<', '>', \"'\"]\n",
    "space_char = ['\\n', '\\t', ',']\n",
    "tweets = []\n",
    "treinamento_parcial = pd.DataFrame()\n",
    "\n",
    "for tweet in treinamento.Tweets:\n",
    "    x = ''\n",
    "    for i in range(len(tweet)):\n",
    "        if tweet[i] in UNICODE_EMOJI:\n",
    "            x = x + ' ' + tweet[i] + ' '\n",
    "        elif tweet[i] in space_char:\n",
    "            x = x + ' '\n",
    "        elif tweet[i] not in bad_char:\n",
    "            x = x + tweet[i]\n",
    "    tweets.append(x)\n",
    "treinamento_parcial['Tweets'] = tweets\n",
    "treinamento_parcial['Classificação'] = treinamento['Classificação']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "treinamento_limpo = pd.DataFrame()\n",
    "tweets = []\n",
    "tweet_final = ' '\n",
    "for tweet in treinamento_parcial.Tweets:\n",
    "    limpa_palavras = []\n",
    "    lista_palavras = tweet.split(' ')\n",
    "    for palavra in lista_palavras:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            limpa_palavras.append(palavra)\n",
    "        elif len(palavra) > 2 and palavra[:4] != 'http' and palavra[0] != '@' \\\n",
    "        and palavra[0] != '#':\n",
    "            limpa_palavras.append(palavra)\n",
    "    tweets.append(tweet_final.join(limpa_palavras))\n",
    "treinamento_limpo['Tweets'] = tweets\n",
    "treinamento_limpo['Classificação'] = treinamento['Classificação']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listando todas as palavras e contando o número de palavras que pertencem a tweets relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "every_word = []\n",
    "\n",
    "for i in range(len(treinamento_limpo['Tweets'])):\n",
    "    lista_palavras = treinamento_limpo['Tweets'][i].split(' ')\n",
    "    for palavra in lista_palavras:\n",
    "        if palavra not in every_word:\n",
    "            every_word.append(palavra)\n",
    "            \n",
    "words_relevante = 0\n",
    "words_nao_relevante = 0\n",
    "\n",
    "for i in range(len(treinamento_limpo['Tweets'])):\n",
    "    lista_palavras = treinamento_limpo['Tweets'][i].split(' ')\n",
    "    if treinamento_limpo['Classificação'][i] == 1:\n",
    "        for palavra in lista_palavras:\n",
    "            words_relevante += 1\n",
    "    else:\n",
    "        for palavra in lista_palavras:\n",
    "            words_nao_relevante += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicionarios com a frequencia das palavras: (Laplace Smoothing já implementado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevante = {}\n",
    "nao_relevante = {}\n",
    "\n",
    "for word in every_word:\n",
    "    relevante[word] = 1\n",
    "    nao_relevante[word] = 1\n",
    "\n",
    "for i in range(len(treinamento_limpo['Tweets'])):\n",
    "    lista_palavras = treinamento_limpo['Tweets'][i].split(' ')\n",
    "    if treinamento_limpo['Classificação'][i] == 1:\n",
    "        for palavra in lista_palavras:\n",
    "            relevante[palavra] += 1\n",
    "    else:\n",
    "        for palavra in lista_palavras:\n",
    "            nao_relevante[palavra] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a P( palavra | relevante ) e P( palavra | não relevante ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_relevante = {}\n",
    "P_nao_relevante = {}\n",
    "\n",
    "for palavra in every_word:\n",
    "    P_relevante[palavra] = relevante[palavra] / (words_relevante + len(every_word))\n",
    "    P_nao_relevante[palavra] = nao_relevante[palavra] / (words_nao_relevante + len(every_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando P( relevante ) e P( não relevante ):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_rel = 0\n",
    "S_nrel = 0\n",
    "for valor in treinamento_limpo['Classificação']:\n",
    "    if valor == 1:\n",
    "        S_rel += 1\n",
    "    else:\n",
    "        S_nrel += 1\n",
    "        \n",
    "P_rel = S_rel / len(treinamento_limpo['Classificação'])\n",
    "P_nrel = S_nrel / len(treinamento_limpo['Classificação'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Lendo a planilha de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste = pd.read_excel('tweets_xbox_teste.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpando a planilha de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_char = [':', '.', ';', '\"', '?', '!', '{', '}', '*', '$', '[', ']', '(', ')', '/', '&', '<', '>', \"'\"]\n",
    "space_char = ['\\n', '\\t', ',']\n",
    "tweets = []\n",
    "teste_parcial = pd.DataFrame()\n",
    "\n",
    "for tweet in teste.Tweets:\n",
    "    x = ''\n",
    "    for i in range(len(tweet)):\n",
    "        if tweet[i] in UNICODE_EMOJI:\n",
    "            x = x + ' ' + tweet[i] + ' '\n",
    "        elif tweet[i] in space_char:\n",
    "            x = x + ' '\n",
    "        elif tweet[i] not in bad_char:\n",
    "            x = x + tweet[i]\n",
    "    tweets.append(x)\n",
    "teste_parcial['Tweets'] = tweets\n",
    "teste_parcial['Classificação'] = teste['Classificação']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_limpo = pd.DataFrame()\n",
    "tweets = []\n",
    "tweet_final = ' '\n",
    "for tweet in teste_parcial.Tweets:\n",
    "    limpa_palavras = []\n",
    "    lista_palavras = tweet.split(' ')\n",
    "    for palavra in lista_palavras:\n",
    "        if palavra in UNICODE_EMOJI:\n",
    "            limpa_palavras.append(palavra)\n",
    "        elif len(palavra) > 2 and palavra[:4] != 'http' and palavra[0] != '@' \\\n",
    "        and palavra[0] != '#':\n",
    "            limpa_palavras.append(palavra)\n",
    "    tweets.append(tweet_final.join(limpa_palavras))\n",
    "teste_limpo['Tweets'] = tweets\n",
    "teste_limpo['Classificação'] = teste['Classificação']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevendo se um tweet é relevante ou não:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = []\n",
    "for tweet in teste_limpo['Tweets']:\n",
    "    prob_r = 1\n",
    "    prob_nr = 1\n",
    "    frase = tweet.split(' ')\n",
    "    for palavra in frase:\n",
    "        if palavra in P_relevante:\n",
    "            prob_r *= P_relevante[palavra]\n",
    "        else:\n",
    "            prob_r *= (1 / (words_relevante + len(every_word)))\n",
    "    for palavra in frase:\n",
    "        if palavra in P_nao_relevante:\n",
    "            prob_nr *= P_nao_relevante[palavra]\n",
    "        else:\n",
    "            prob_nr *= (1 / (words_nao_relevante + len(every_word)))\n",
    "    relevant = prob_r * P_rel\n",
    "    not_relevant = prob_nr * P_nrel\n",
    "    if relevant > not_relevant:\n",
    "        previsao.append(1)\n",
    "    else:\n",
    "        previsao.append(0)\n",
    "    \n",
    "teste_limpo['Previsão'] = previsao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando as medidas pedidas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentagem de positivos falsos: 22.50%\n",
      "Porcentagem de positivos verdadeiros: 13.50%\n",
      "Porcentagem de negativos verdadeiros: 55.50%\n",
      "Porcentagem de negativos falsos: 8.50%\n"
     ]
    }
   ],
   "source": [
    "prcr = 0\n",
    "pnrcr = 0\n",
    "prcnr = 0\n",
    "pnrcnr = 0\n",
    "\n",
    "for i in range(len(teste_limpo['Previsão'])):\n",
    "    if teste_limpo['Previsão'][i] == 1 and teste_limpo['Classificação'][i] == 1:\n",
    "        prcr += 1\n",
    "    elif teste_limpo['Previsão'][i] == 0 and teste_limpo['Classificação'][i] == 1:\n",
    "        pnrcr += 1\n",
    "    elif teste_limpo['Previsão'][i] == 1 and teste_limpo['Classificação'][i] == 0:\n",
    "        prcnr += 1\n",
    "    else:\n",
    "        pnrcnr += 1\n",
    "        \n",
    "P_pos_falso = prcnr / len(teste_limpo['Classificação'])\n",
    "P_pos_verdadeiro = prcr / len(teste_limpo['Classificação'])\n",
    "P_neg_verdadeiro = pnrcnr / len(teste_limpo['Classificação'])\n",
    "P_neg_falso = pnrcr / len(teste_limpo['Classificação'])\n",
    "\n",
    "print('Porcentagem de positivos falsos: {0:.2f}%'.format(P_pos_falso * 100))\n",
    "print('Porcentagem de positivos verdadeiros: {0:.2f}%'.format(P_pos_verdadeiro * 100))\n",
    "print('Porcentagem de negativos verdadeiros: {0:.2f}%'.format(P_neg_verdadeiro * 100))\n",
    "print('Porcentagem de negativos falsos: {0:.2f}%'.format(P_neg_falso * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O classificador prevê a relevância de um tweet corretamente em 69.00% dos casos.\n"
     ]
    }
   ],
   "source": [
    "acertos = 0\n",
    "for i in range(len(teste_limpo['Previsão'])):\n",
    "    if teste_limpo['Previsão'][i] == teste_limpo['Classificação'][i]:\n",
    "        acertos += 1\n",
    "        \n",
    "accuracy = acertos / len(teste_limpo)\n",
    "\n",
    "print('O classificador prevê a relevância de um tweet corretamente em {0:.2f}% dos casos.'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparação Qualitativa das Medidas Obtidas**\n",
    "\n",
    "O classificador apresentou uma acurácia de 69%, o que significa que acertou a classificação de 69% dos tweets da base de teste. Além disso, apresentou precisão de 22.5% na classificação de tweets positivos falsos, ou seja, tweets relevantes marcados como irrelevantes e 13.5% de tweets positivos verdadeiros, ou seja, tweets relevantes marcados como tal. Em relação aos negativos falsos, ou seja, tweets irrelevantes marcados como relevantes, a precisão foi de 8.5% e em relação aos negativos verdadeiros, ou seja, tweets irrelevantes marcados como irrelevantes, a precisão foi de 55.5%. \n",
    "\n",
    "**Mensagens com Dupla Negação e Sarcasmo**\n",
    "\n",
    "O classificador não é capaz de entender quando o tweet apresenta mensagens de dupla negação ou sarcasmo pois como o próprio nome do algoritmo (Naive-Bayes) já indica ('Naive' em inglês significa 'ingênuo'), este desconsidera a correlação entre as variáveis, ou seja, as analisa individualmente e não considera o que a presença delas, por exemplo, num mesmo tweet, significa. Desta forma, o classificador não é capaz de entender expressões que apresentem dupla negação, já que classificaria ambas as negações individualmente e não o que a presença das duas juntas significa e nem de identificar expressões sarcasticas, já que estas dependem de contexto e o algoritmo trabalha com variávies independentes.\n",
    "\n",
    "**Plano de Expansão**\n",
    "\n",
    "Este classificador é muito útil para as empresas pois facilita sua comunicação com o consumidor, já que reduz a quantidade total de tweets para menos que a metade, deixando com alta precisão apenas os tweets relevantes em relação a determinado produto, pode economizar tempo de um funcionário responsável por responder consumidores nas redes sociais e permite que a empresa encontre um feedback dos usuários de forma mais ágil. O financiamento do projeto permitiria que fossem feitas melhorias em relação à limpeza da base de dados e permitiria que fossem coletados um número maior de tweets, o que resultaria numa precisão ainda maior na seleção de tweets relevantes, tornando os processos de feedback ao usuário e absorção do feedback dado por este mais eficazes.\n",
    "\n",
    "\n",
    "**Alimentação da Base de Treinamento**\n",
    "\n",
    "Não é possível alimentar a base de dados do Treinamento automaticamente utilizando o próprio classificador, aplicado a novos tweets, pois este não possui conhecimento suficiente para classificar corretamente qualquer tipo de tweet. Desta forma, a classificação dos novos tweets seria enviesada, devido à incapacidade do classificador de identificar expressões que apresentem, por exemplo, dupla negação e sarcasmo. \n",
    "\n",
    "\n",
    "**Diferentes Cenários para o Uso de Naive-Bayes**\n",
    "\n",
    "O Naive-Bayes é um algoritmo que pode ser utilizado com diversas finalidades, mas sempre trabalhando com probabilidade de variáveis. Desta forma, pode ser utilizado, por exemplo, para identificar a partir de uma descrição qual ser vivo está sendo descrito. Neste caso, no entanto, não poderiam haver seres com mesma característica, já que o algoritmo é incapaz de classificar baseado em um conjunto de variáveis, analisando independentemente cada uma delas. Ou seja, se o usuário deseja, por exemplo, saber se certa descrição se refere a um tipo de animal ou a um tipo de planta, ele pode usar o Naive-Bayes para calcular a probabilidade de cada palavra da descrição ser referente a cada um dos seres e chegar a uma resposta. \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
